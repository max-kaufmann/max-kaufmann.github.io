<head>
    <link rel="stylesheet" href="../site_libs/bootstrap/bootstrap.min.css">
</head>

<strong>The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A"</strong><br>
Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, Owain Evans<br>
<a href="https://arxiv.org/abs/2309.12288" target="_parent">[arxiv]</a>
<a href="https://twitter.com/OwainEvans_UK/status/1698683186090537015" target="_parent">[tweet]</a><br><br>

<strong>Taken out of context: On measuring situational awareness in LLMs</strong><br>
Lukas Berglund*, Asa Cooper Stickland*, Mikita Balesni*, Max Kaufmann*, Meg Tong*, T. Korbak, D. Kokotajlo, O. Evans<br>
<a href="https://arxiv.org/abs/2309.00667" target="_parent">[arxiv]</a>
<a href="https://x.com/OwainEvans_UK/status/1705285631520407821" target="_parent">[tweet]</a><br><br>

<strong>Testing Robustness Against Unforeseen Adversaries</strong><br>
Max Kaufmann*, Daniel Kang*, Yi Sun*, Steven Basart, Xuwang Yin, Mantas Mazeika, Akul Arora, Adam Dziedzic, Franziska Boenisch, Tom Brown, Jacob Steinhardt, Dan Hendrycks<br>
<a href="https://arxiv.org/abs/1908.08016" target= "_parent" >[arxiv]</a><br><br>

<strong>Efficient Adversarial Training With Data Pruning</strong><br>
Max Kaufmann, Yiren Zhao, Ilia Shumailov, Robert Mullins, Nicolas Papernot<br>
<a href="https://arxiv.org/abs/2207.00694" target="_parent" >[arxiv]</a><br><br>


<strong>Dual-use biology capabilities across model scale</strong><br>
Max Kaufmann, Gryphon Scientific, Jonas Sandbrink<br>
<i>Presented to policymakers at the 2023 International AI Safety Summit.</i>
<br><br>

<strong>MatAttack: Differential materials for adversarial attacks</strong><br>
Dron Hazra*, Max Kaufmann*, Dan Hendrycks<br><i> forthcoming </i>



  