<head>
    <link rel="stylesheet" href="../site_libs/bootstrap/bootstrap.min.css">
</head>

<strong>The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A"</strong><br>
Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, Owain Evans<br>
<a href="https://arxiv.org/abs/2309.12288">[arxiv]</a>
<a href="https://twitter.com/OwainEvans_UK/status/1698683186090537015">[tweet]</a><br>

<strong>Taken out of context: On measuring situational awareness in LLMs</strong><br>
Lukas Berglund\*, Asa Cooper Stickland\*, Mikita Balesni\*, Max Kaufmann\*, Meg Tong\*, T. Korbak, D. Kokotajlo, O. Evans<br>
<a href="https://arxiv.org/abs/2309.00667">[arxiv]</a>
<a href="https://x.com/OwainEvans_UK/status/1705285631520407821">[tweet]</a><br>
<br>

<strong>Testing Robustness Against Unforeseen Adversaries</strong><br>
Max Kaufmann\*, Daniel Kang\*, Yi Sun\*, Steven Basart, Xuwang Yin, Mantas Mazeika, Akul Arora, Adam Dziedzic, Franziska Boenisch, Tom Brown, Jacob Steinhardt, Dan Hendrycks<br>
<a href="https://arxiv.org/abs/1908.08016">[arxiv]</a><br>
<br>

<strong>Efficient Adversarial Training With Data Pruning</strong><br>
Max Kaufmann, Yiren Zhao, Ilia Shumailov, Robert Mullins, Nicolas Papernot<br>
<a href="https://arxiv.org/abs/2207.00694">[arxiv]</a><br>
<br>

<strong>MatAttack: Differential materials for adversarial attacks</strong><br>
Dron Hazra\*, Max Kaufmann\*, Dan Hendrycks<br><i> forthcoming </i>
<br>


<strong>Dual-use biology capabilities across model scale</strong><br>
Max Kaufmann, Gryphon Scientific, Jonas Sandbrink<br>
<i>Presented to policymakers at the 2023 International AI Safety Summit.</i>
<br>



  